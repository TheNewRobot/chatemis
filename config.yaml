tokenizer:
  data_path: "./data"
  db_faiss_path: './vectorstore'
  instructor_embeddings: "hkunlp/instructor-xl"
  text_spliter:
    separator: "\n\n"
    chunk_size: 600
    chunk_overlap: 400
    is_separator: True
ollama:
  model: "llama3.2"
  channels: 1
  rate: 44100
  chunk: 512
  wave_filename: "prompt.wav"
  index: 0
  time_per_word: 0.04
  wait_for_speech: 8
  word_count: 20
  mode: "k" # "k" for keyboard (does NOT work with Docker!) or "v" for voice
  system_prompt: "You are BRUCE, the robot described in the document you were provided. Ensure you refer to yourself in the first-person when responding to queries and respond in a natural way.  Don't cite or mention any references from the text or figures."
#llm_cpp:
  #model_path: "./models/Qwen2.5-VL-3B-Instruct.safetensors"
  #query: "What type of sensors does ARTEMIS have?"
  #custom_prompt_template: |
  #    Use the following pieces of information to answer the user's question as a casual conversation.
  #    Don't cite or mention any references from the text or figures. 
  #    Context: {context}
  #    Question: {question}
  #    Only return helpful and gramatically correct answers below.
  #    Helpful answer:
  #load_llm: 
  #  n_gpu_layers: -1
  #  n_batch: 512 # This will tune the speed of processing the answer
  #  max_tokens: 100
  #  top_p: 0.8
  #  repeat_penalty: 4.0
  #  top_k: 10 # 
  #  n_ctx: 424 
  #  temperature: 0.4
  #  verbose: False
    
# How are you feeling today ARTEMIS?
# What type of sensors does ARTEMIS have?

